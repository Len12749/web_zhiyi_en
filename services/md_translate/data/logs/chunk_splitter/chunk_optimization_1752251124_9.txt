===== 文本块对 9 =====

===== LLM PROMPT =====

您是一位专精于文档处理的AI助手。我需要您优化两个连续文本块之间的截断点，使得每个块在语义上更加完整，便于后续单独处理（如翻译）时保持正确的上下文。

您的任务是:
1. 分析这两个文本块的语义内容
2. 确定最佳的语义断点位置
3. 重新分配文本内容，使每个块在语义上更完整
4. 确保输出格式使用markdown内联latex格式，保持数学公式的正确性

输入的两个文本块:
{
"text_a": "To control for the truncation error, we take advantage of the fact that $I(u)$ is explicit, and study its asymptotic behavior for large $u$ : In particular, we can show that, for large enough $u$ ; $|I_{1}(u)|\\leqslant\\exp(-u A_{1}+A_{0})$ where $A_{1}=(v+$ $\\bar{v}^{*}\\kappa^{*}\\tau)\\sqrt{1-\\rho^{2}}/\\bar{\\sigma_{v}}$ ; and $A_{0}=(v+\\bar{v}^{*}\\kappa^{*}\\tau)(\\kappa^{*}-\\sigma_{v}\\rho)/\\sigma_{v}^{2}+\\ln(4(1-\\rho^{2}))\\kappa^{*}\\bar{v}^{*}/\\sigma_{v}^{2}$ : For the desired accuracy $\\delta$ ; we can therefore choose $U_{1}$ such that\n\n$$\n\\frac{1}{\\pi A_1 U_1} \\exp \\left( -A_1 U_1 + A_0 \\right) \\leq \\delta.\n$$\n\nTo control for the discretization error, we focus on the probabilities $\\mathrm{P}(\\tilde{X}_{1}<\\bar{x}-$ $2\\pi/\\Delta u_{1})$ and $\\mathrm{P}(\\tilde{X}_{1}>\\bar{x}-2\\pi/\\Delta u_{1})$ ; which sample further into the left and right tails as $\\Delta u_{1}$ approaches to zero. Given that the mean $\\mu_{X_{1}}$ and variance $\\sigma_{X_{1}}^{2}$ of ${\\tilde{X}}_{1}$ are finite, the tail probabilities can be controlled by Chebyshev\u2019s inequality:\n\n$$\nP\\left(\\left|\\tilde{X}_1 - \\mu_{X_1}\\right| > \\frac{\\sigma_{X_1}}{\\sqrt{\\delta}}\\right) < \\delta. \\tag{B.13}\n$$\n\nWe can therefore establish an upper bound in probability for the two tail events $\\{\\tilde{X}_{1}-\\mu_{X_{1}}>\\sigma_{X_{1}}/\\sqrt{\\delta}\\}$ and $\\{\\hat{\\tilde{X}}_{1}-\\mu_{X_{1}}<-\\sigma_{X_{1}}\\hat{\\tilde{/}}\\sqrt{\\delta}\\}$ : The discretization step $\\Delta u_{1}$ can be chosen such that\n\n$$\n\\frac{2\\pi}{\\Delta u_1} = \\max(\\bar{x} - \\mu_{X_1}, \\mu_{X_1} - \\bar{x}) + \\frac{\\sigma_{X_1}}{\\sqrt{\\delta}} \\tag{B.14}\n$$\n\nTo calculate the mean and variance of $\\tilde{X}_{1}$ ; we again take advantage of its explicitly known characteristic function $\\tilde{\\psi}_{1}(\\cdot)$ : Specifically, for any $u\\in\\mathbb{R}$ ; the moment-generating function of $\\tilde{X}_{1}$ is E[exp $(u\\tilde{X_{1}})]=\\tilde{\\psi}_{1}(-\\mathrm{i}u)$ ; from which its mean and variance can be derived accordingly.\n\nThe numerical integration scheme used for ${\\mathcal{P}}_{2}$ is similar. Details are omitted, and are available upon request.\n\n<!-- Page:35 -->\n\n## Appendix C. Large-sample properties of IS-GMM estimators\n\nAn inherent feature of exchange-traded options is that certain contract variables, such as time $\\tau_{n}$ to expiration and strike-to-spot ratio $k_{n}$ ; vary over time. As the option-implied stochastic volatility $V_{n}^{\\vartheta}$ depends on $\\tau_{n}$ and $k_{n}$ ; this variation in contract variables introduces a form of nuisance-dependency to the moment conditions that may affect the large-sample properties of the IS-GMM estimators. In this appendix, we establish the strong consistency and asymptotic normality of ISGMM estimators under assumptions of weak time-stationarity of $\\left\\{\\tau_{n}\\right\\}$ and geometric ergodicity of $\\{y_{n},V_{n},r_{n},q_{n},k_{n}\\}$ : The results established in this section could be useful in other applications using exchange-traded derivative securities.[^1]\n\n### C.1. Stationarity assumption for contract variables\n\nTo motivate our assumptions for the contract variables, we recall from Fig. 2 that $\\left\\{\\tau_{n}\\right\\}$ is \u2018\u2018repetitive,\u2019\u2019 in an almost deterministic fashion according to the business calendar, while $\\{k_{n}\\}$ evolves in a random fashion that can be thought of as a sample path drawn from a stationary process.\n\nThe nearly periodic feature of $\\left\\{\\tau_{n}\\right\\}$ makes the usual mixing conditions difficult to justify. For example, suppose that $\\left\\{\\tau_{n}\\right\\}$ is of the form $(40,33,26,19,40,33,26,19,...)$ . Then on date $n$ ; depending on where we start initially, $\\tau_{n}$ can be 40, 33, 26, or 19. Effectively, this chain has an infinitely long \u2018\u2018memory,\u2019\u2019 contrary to the mixing property.[^2] In this paper, we take an alternative approach, and assume that $\\left\\{\\tau_{n}\\right\\}$ takes only finitely many outcomes, and satisfies a time-stationarity property (See Assumption C.1 below) that is weaker than typical mixing conditions. In the above example, for instance, $\\left\\{\\tau_{n}\\right\\}$ is time stationary because the fraction of observations for which $\\tau_{n}=40$ converges to 0.25, and likewise for each of the other outcomes of $\\tau_{n}$ : Such an assumption of finitely many outcomes is characteristic of many derivative contract variables, such as the indicator for \u2018\u2018put\u2019\u2019 versus \u2018\u2018call,\u2019\u2019 the exchange identity (for example, CBOE, CME, or PHLX) from which the derivative securities are observed, the maturity of the underlying instruments (in the case of interest-rate derivatives), or multiple selections of an underlying.\n\nAn appropriate stationarity assumption for the dynamic behavior of the strike-tospot ratio $\\{k_{n}\\}$ is not as clear. In particular, the evolution of $\\{k_{n}\\}$ could be quite complicated, depending on the evolution over time of the strike-price grid, which is driven by detailed institutional features of the equity index option market. In this\n\n---\n\n[^1]: For exchange-traded derivatives, this situation of tme-varying contract variables almost always arises. In over-the-counter markets, however, contract variables on regularly quoted derivative prices are usually constant over time. See Brandt and Santa-Clara (2001) for an application to over-the-counter derivatives.\n\n[^2]: The \u201cmixing property of aMarkov chain canbeintuitively explainedbya physical analogue t location of a particle or gaseous mixture becomes less and less dependent on its initial position as time progress. See Gallant and White (1988) and references therein.\n\n<!-- Page:36 -->\n\npaper, our consistency result can be based on the assumption that $\\{k_{n}\\}$ is, joint with $\\left\\{y_{n},V_{n},q_{n},r_{n}\\right\\}$ ; geometrically ergodic, as stated more precisely below.\n\n### C.2. Consistency\n\nWe start with a formal definition of the option-implied volatility introduced in Section 3.1. Let $\\Xi\\subset[0,1]\\times\\Theta\\times\\mathbb{R}_{+}\\times\\mathbb{R}_{+}\\times\\mathbb{R}_{+}\\times\\mathbb{R}_{+}$ denote the domain of invertibility (with respect to volatility) of the option-pricing function $f$ of Eq. (3), in that $\\Xi$ is the maximal set for which a mapping $g:\\Xi\\to\\mathbb{R}_{+}$ is uniquely defined by\n\n$$\nf(g(c,\\, \\theta,\\, r,\\, q,\\, \\tau,\\, k),\\, \\theta,\\, r,\\, q,\\, \\tau,\\, k) = c \\tag{C.1}\n$$\n\nfor all $(c,\\vartheta,r,q,\\tau,k)\\in\\Xi$ : We suppose that the parameter space $\\boldsymbol{\\Theta}$ is defined so that, for any observation date $n$ and all $\\vartheta\\in\\Theta$ ; we have $(c_{n},\\vartheta,r_{n},q_{n},\\tau_{n},k_{n})\\in\\Xi$ : In effect, this is a joint property of the data and $\\boldsymbol{\\Theta}$ ; akin to an assumption that the model is not shown to be mis-specified. Indeed, in the empirical results to follow, inversion was possible at all data points. For any $\\boldsymbol{\\vartheta}\\in\\boldsymbol{\\Xi}$ ; we can therefore define the date- $n$ optionimplied volatility by\n\n$$\nV_{n}^{g} = g(c_n, \\vartheta, r_n, q_n, \\tau_n, k_n). \\tag{C.2}\n$$",
"text_b": "We next establish the link between the option-implied volatility $V_{n}^{\\vartheta}$ and the true volatility state variable $V_{n}$ by letting $V_{n}^{9}=\\nu(V_{n}^{A},\\:\\mathbb{\\vec{y}},r_{n}^{A},q_{n}^{A},\\tau_{n},{\\:\\ddot{k}_{n}})$ ; where $\\nu$ : $\\mathbb{R}_{+}\\times\\theta\\times\\mathbb{R}_{+}\\times\\mathbb{R}_{+}\\times\\mathbb{R}_{+}\\times\\mathbb{R}_{+}\\to\\mathbb{R}_{+}$ is defined by\n\n$$\nv(v, \\vartheta, r, q, \\tau, k) = g(f(v, \\vartheta_0, r, q, \\tau, k), \\vartheta, r, q, \\tau, k), \\tag{C.3}\n$$\n\nwhere $g$ is defined by Eq. (C.1), using the fact that $c_{n}=f(V_{n}^{A},\\vartheta_{0},r_{n}^{A},q_{n}^{A},\\tau_{n},k_{n})$ : We note that $\\nu(v,\\vartheta_{0},r,q,\\tau,k)=v.$ :\n\nLetting $X_{n}=[y_{(n,n_{y})},V_{(n,n_{v})},r_{(n,n_{v})},q_{(n,n_{v})},k_{(n,n_{v})}]$ denote the \u2018 $\\mathbf{\\dot{\\rho}}_{n_{y}}$ -history\u2019\u2019 of $y$ and the \u2018 $\\cdot_{n_{v}}$ -histories\u2019\u2019 of $r,q,k_{;}$ ; and $\\tau$ ; and letting $Y_{n}=\\tau_{(n,n_{v})}$ denote the \u2018 $n_{v}$ -history\u2019\u2019 of $\\tau$ ; we write\n\n$$\nH(X_n, \\theta, Y_n) = h(y(n, n_y), v(V(n, n_v), \\theta, r(n, n_v), q(n, n_v), \\tau(n, n_v), k(n, n_v)), \\theta), \\tag{C.4}\n$$\n\nwhere $r_{(n,n_{v})}=[r_{n},r_{n-1},...,r_{n-n_{v}+1}],$ and, analogously, $q_{(n,n_{v})},k_{(n,n_{v})}$ ; and $\\tau_{(n,n_{v})}$ are the $n_{v}$ -dimensional vectors consisting of $q_{n},k_{n},\\tau_{n}$ ; and their respective lags. As outlined in the previous subsection, reasonable stationarity assumptions for $X$ and $Y$ are rather different, and are treated separately.\n\nAssumption C.1. (Time stationarity of $Y_{c}$ ). $\\{Y_{n}\\}$ has finitely many outcomes, denoted $\\{1,2,...,I\\}$ : For each outcome $i$ and each positive integer $N$ ; let $A_{N}^{(i)}=\\{n\\leqslant N:$ $Y_{n}=i\\}$ be the dates, up to $N$ ; on which $Y$ has outcome $i$ : For each $i.$ ; there is some $w_{i}\\in[0,1],$ such that\n\n$$\n\\lim_{N} \\frac{\\#A_N^{(i)}}{N} = w_i \\quad \\text{a.s.} \\tag{C.1}\n$$\n\nwhere $\\#(\\cdot)$ denotes cardinality.\n\n<!-- Page:37 -->\n\nFor a proof of the geometric ergodicity of the state vector $\\{y_{n},~V_{n},~r_{n},~q_{n}\\}$ ; see Appendix B.9 of Pan (2000). Assuming further that $\\{k_{n}\\}$ and $\\{y_{n},~V_{n},~r_{n},~q_{n}\\}$ are jointly geometrically ergodic, we know that $X_{n}=[y_{(n,n_{v})},V_{(n,n_{y})},r_{(n,n_{v})},$ ; $q_{(n,n_{v})},k_{(n,n_{v})}]$ is geometrically ergodic, since it includes only finitely many lags of the joint process.\n\nAssumption C.2. (USLLN of $\\boldsymbol{A}^{(i)}$ -sampling). For each outcome i of $Y$ ; letting\n\n$$\nG_N^{(i)}(\\theta) = \\frac{1}{\\#A_N^{(i)}} \\sum_{n \\in A_N^{(i)}} H(X_n, \\theta, i),\n$$\n\n$G_{\\infty}^{(i)}(\\vartheta)=\\mathrm{lim}_{N}G_{N}^{(i)}(\\vartheta)$ exists (pointwise SLLN), and\n\n$$\n\\sup_{\\theta \\in \\Theta} \\left| G_N^{(i)}(\\theta) - G_\\infty^{(i)}(\\theta) \\right| \\rightarrow 0 \\quad \\text{a.s.} \\tag{C.6}\n$$\n\nGiven the pointwise-SLLN portion of Assumption C.2, in order to establish the uniform SLLN of Assumption C.2, it is typical to assume some form of Lipschitz condition on $H(x,\\vartheta,i)$ as a function of W: Examples of such conditions include the Lipschitz and derivative conditions of Andrews (1987) and the first-momentcontinuity condition of Hansen (1982).\n\nWe now establish the uniform strong law of large numbers (USLLN) of $\\{H(X_{n},{\\mathcal{Y}},Y_{n})\\}$ ; key step to establishing the strong consistency of $\\{\\hat{\\mathcal{\\vartheta}}_{n}\\}$ : A proof can be found in Appendix B.8 in Pan (2000).\n\nProposition C.1. (USLLN of $H(X,~\\vartheta,~Y))$ . Under Assumptions C.1 and C.2, for each W; $G_{\\infty}(\\vartheta)=\\mathrm{lim}_{N}G_{N}(\\vartheta)$ exists, and\n\n$$\n\\sup_{\\theta \\in \\Theta} |G_N(\\theta) - G_{\\infty}(\\theta)| \\to 0 \\quad \\text{a.s.},\n$$\n\nwhere $G_{N}(\\mathcal{B})$ ; defined by Eq. (5), is the sample moment of the observation function.\n\nFinally, to show strong consistency of the IS-GMM estimator $\\{\\hat{\\mathcal{\\vartheta}}_{n}\\}$ ; we adopt the following two standard assumptions.\n\nAssumption C.3 (Convergence of weighting matrices). $\\mathcal{W}_{N}\\rightarrow\\mathcal{W}_{0}$ almost surely for some constant symmetric positive-definite matrix $\\mathcal{W}_{0}$ :\n\nUnder Assumption C.3 and the conditions of Proposition C.1, the criterion function $C_{N}(\\boldsymbol{\\vartheta})\\overset{\\cdot}{=}G_{N}(\\boldsymbol{\\vartheta})^{\\top}\\mathcal{W}_{N}G_{N}(\\boldsymbol{\\vartheta})$ converges almost surely to the asymptotic criterion function $C:\\Theta\\to\\mathbb{R}$ defined by $C_{N}(\\overset{\\cdot}{\\vartheta})=G_{\\infty}(\\vartheta)^{\\top}\\mathcal{W}_{N}\\overset{\\cdot}{G}_{\\infty}(\\vartheta)$ : In particular, we have $G(\\vartheta_{0})=0$ ; given the moment condition Eq. (2), the pointwise-SLLN portion of Proposition C.1, and the fact that $V_{n}^{9_{0}}=V_{n}^{\\varDelta}$ :\n\nAssumption C.4 (Uniqueness of minimizer). $C(\\vartheta)\\neq G(\\vartheta_{0}),\\vartheta\\in\\Theta,\\vartheta\\neq\\vartheta_{0}.$ :\n\n<!-- Page:38 -->\n\nTheorem C.1 (Strong consistency). Under Assumptions C.1\u2013C.4. the IS-GMM $\\{\\vartheta_{N}\\}$ estimator converges to $\\mathcal{\\mathrm{\\vartheta}}_{0}$ almost surely as $N\\to\\infty$ .\n\nGiven the Uniform SLLN (Proposition C.1), the proof is standard and omitted. (See, for example, the proof of Theorem 3.3 in Gallant and White, 1988.)\n\n#### C.2.1. Asymptotic normality\n\nNext, we establish asymptotic normality for the IS-GMM estimator, allowing for time-varying contract variables. Because $\\nu(v,\\vartheta_{0},r,q,\\tau,k)=v$ ; the sample moment $G_{N}(\\mathcal{B})$ evaluated at the true parameter $\\vartheta_{0}$ does not depend on the contract variables $\\{\\tau_{n},k_{n}\\}$ : Given the consistency result above, the asymptotic normality of $\\sqrt{N}G_{N}(\\mathcal{G}_{0})$ therefore depends only on the properties of $(y,V)$ and $h$ via a standard form of central limit theorem (CLT).\n\nAssumption C.5 (CLT). $\\sqrt{N}G_{N}(\\mathcal{vartheta}_{0})$ converges in distribution as $N\\to\\infty$ to a normal random vector with mean zero and some covariance matrix $\\scriptstyle\\sum_{0}$ :\n\nThis assumption follows immediately from the geometric ergodicity of $(y,V)$ and an assumption of integrability of $\\left|\\left|h(y_{(n,n_{y})},V_{(n,n_{v})})\\right|\\right|^{2+\\delta}$ ; for some $\\delta>0$ ; over the stationary distribution of $(y_{(n,n_{y})},\\dot{V_{(n,n_{v})}})$ . (See, for example, Theorem 7.5 of Doob, 1953; the proof of Theorem 4 of Duffie and Singleton, 1993.)\n\nThe asymptotic normality of $\\sqrt{N}(\\mathcal{\\vartheta}_{N}-\\mathcal{\\vartheta})$ depends further on the local behavior of the observation functions in a neighborhood of $\\vartheta_{0}$ ; and is influenced by the contract variables $\\{\\tau_{n},k_{n}\\}$ : For this, we consider the derivative $d(\\vartheta,X_{n},Y_{n})$ of $H(X_{n},{\\mathcal{S}},Y_{n})$ with respect to W; defined by\n\n$$\nd(\\vartheta, X_{n}, Y_{n}) = \\frac{\\partial}{\\partial \\vartheta} h\\left( y(n, n_{y}), \\; V^{\\vartheta}_{(n, n_{v})}, \\; \\vartheta \\right) \\\\ + \\sum_{i=n-n_{v}+1}^{n} \\frac{\\partial}{\\partial v_{i}} h\\left( y(n, n_{y}), \\; V^{\\vartheta}_{(n, n_{v})}, \\; \\vartheta \\right) g_{\\vartheta}\\left( c_{i}, \\; \\vartheta, \\; r_{i}^{A}, \\; q_{i}^{A}, \\; \\tau_{i}, \\; k_{i} \\right), \\tag{C.7}\n$$"
}

请严格按照以下JSON格式返回优化后的两个文本块:
{
"text_a": "优化后的第一个文本块",
"text_b": "优化后的第二个文本块"
}

重要说明:
- 保持所有原始内容的完全一致，不要添加或删除信息
- 只调整两个文本块之间的截断点位置
- 避免在表格、图表、公式、代码块等结构化内容中间截断
- 确保输出使用markdown内联latex格式，行内公式使用单个`$`符号包围，独立公式块使用双`$$`符号包围
- 保持所有数学符号的正确性和一致性
- 请只返回符合要求的JSON格式，不要包含任何其他解释或备注
请遵循以下优化原则:
1. 核心目标是让每个块在独立阅读时尽可能具有完整的语义和结构，例如如果可以识别，脚注内容和正文内容应放在同一个文本块中
2. 表格、图表、公式、代码块等结构化内容应作为整体放在同一个文本块中，不要在其中间截断
3. 优先在段落结束、章节标题前、主题转换处设置截断点
4. 不需要考虑两块文本长度的平衡，只关注语义完整性
5. 对于HTML/Markdown等标记语言，确保标签的完整性，不要截断标签结构


===== LLM RESPONSE =====

```json
{
"text_a": "To control for the truncation error, we take advantage of the fact that $I(u)$ is explicit, and study its asymptotic behavior for large $u$ : In particular, we can show that, for large enough $u$ ; $|I_{1}(u)|\\leqslant\\exp(-u A_{1}+A_{0})$ where $A_{1}=(v+$ $\\bar{v}^{*}\\kappa^{*}\\tau)\\sqrt{1-\\rho^{2}}/\\bar{\\sigma_{v}}$ ; and $A_{0}=(v+\\bar{v}^{*}\\kappa^{*}\\tau)(\\kappa^{*}-\\sigma_{v}\\rho)/\\sigma_{v}^{2}+\\ln(4(1-\\rho^{2}))\\kappa^{*}\\bar{v}^{*}/\\sigma_{v}^{2}$ : For the desired accuracy $\\delta$ ; we can therefore choose $U_{1}$ such that\n\n$$\n\\frac{1}{\\pi A_1 U_1} \\exp \\left( -A_1 U_1 + A_0 \\right) \\leq \\delta.\n$$\n\nTo control for the discretization error, we focus on the probabilities $\\mathrm{P}(\\tilde{X}_{1}<\\bar{x}-$ $2\\pi/\\Delta u_{1})$ and $\\mathrm{P}(\\tilde{X}_{1}>\\bar{x}-2\\pi/\\Delta u_{1})$ ; which sample further into the left and right tails as $\\Delta u_{1}$ approaches to zero. Given that the mean $\\mu_{X_{1}}$ and variance $\\sigma_{X_{1}}^{2}$ of ${\\tilde{X}}_{1}$ are finite, the tail probabilities can be controlled by Chebyshev\u2019s inequality:\n\n$$\nP\\left(\\left|\\tilde{X}_1 - \\mu_{X_1}\\right| > \\frac{\\sigma_{X_1}}{\\sqrt{\\delta}}\\right) < \\delta. \\tag{B.13}\n$$\n\nWe can therefore establish an upper bound in probability for the two tail events $\\{\\tilde{X}_{1}-\\mu_{X_{1}}>\\sigma_{X_{1}}/\\sqrt{\\delta}\\}$ and $\\{\\hat{\\tilde{X}}_{1}-\\mu_{X_{1}}<-\\sigma_{X_{1}}\\hat{\\tilde{/}}\\sqrt{\\delta}\\}$ : The discretization step $\\Delta u_{1}$ can be chosen such that\n\n$$\n\\frac{2\\pi}{\\Delta u_1} = \\max(\\bar{x} - \\mu_{X_1}, \\mu_{X_1} - \\bar{x}) + \\frac{\\sigma_{X_1}}{\\sqrt{\\delta}} \\tag{B.14}\n$$\n\nTo calculate the mean and variance of $\\tilde{X}_{1}$ ; we again take advantage of its explicitly known characteristic function $\\tilde{\\psi}_{1}(\\cdot)$ : Specifically, for any $u\\in\\mathbb{R}$ ; the moment-generating function of $\\tilde{X}_{1}$ is E[exp $(u\\tilde{X_{1}})]=\\tilde{\\psi}_{1}(-\\mathrm{i}u)$ ; from which its mean and variance can be derived accordingly.\n\nThe numerical integration scheme used for ${\\mathcal{P}}_{2}$ is similar. Details are omitted, and are available upon request.\n\n<!-- Page:35 -->\n\n## Appendix C. Large-sample properties of IS-GMM estimators\n\nAn inherent feature of exchange-traded options is that certain contract variables, such as time $\\tau_{n}$ to expiration and strike-to-spot ratio $k_{n}$ ; vary over time. As the option-implied stochastic volatility $V_{n}^{\\vartheta}$ depends on $\\tau_{n}$ and $k_{n}$ ; this variation in contract variables introduces a form of nuisance-dependency to the moment conditions that may affect the large-sample properties of the IS-GMM estimators. In this appendix, we establish the strong consistency and asymptotic normality of ISGMM estimators under assumptions of weak time-stationarity of $\\left\\{\\tau_{n}\\right\\}$ and geometric ergodicity of $\\{y_{n},V_{n},r_{n},q_{n},k_{n}\\}$ : The results established in this section could be useful in other applications using exchange-traded derivative securities.[^1]\n\n### C.1. Stationarity assumption for contract variables\n\nTo motivate our assumptions for the contract variables, we recall from Fig. 2 that $\\left\\{\\tau_{n}\\right\\}$ is \u2018\u2018repetitive,\u2019\u2019 in an almost deterministic fashion according to the business calendar, while $\\{k_{n}\\}$ evolves in a random fashion that can be thought of as a sample path drawn from a stationary process.\n\nThe nearly periodic feature of $\\left\\{\\tau_{n}\\right\\}$ makes the usual mixing conditions difficult to justify. For example, suppose that $\\left\\{\\tau_{n}\\right\\}$ is of the form $(40,33,26,19,40,33,26,19,...)$ . Then on date $n$ ; depending on where we start initially, $\\tau_{n}$ can be 40, 33, 26, or 19. Effectively, this chain has an infinitely long \u2018\u2018memory,\u2019\u2019 contrary to the mixing property.[^2] In this paper, we take an alternative approach, and assume that $\\left\\{\\tau_{n}\\right\\}$ takes only finitely many outcomes, and satisfies a time-stationarity property (See Assumption C.1 below) that is weaker than typical mixing conditions. In the above example, for instance, $\\left\\{\\tau_{n}\\right\\}$ is time stationary because the fraction of observations for which $\\tau_{n}=40$ converges to 0.25, and likewise for each of the other outcomes of $\\tau_{n}$ : Such an assumption of finitely many outcomes is characteristic of many derivative contract variables, such as the indicator for \u2018\u2018put\u2019\u2019 versus \u2018\u2018call,\u2019\u2019 the exchange identity (for example, CBOE, CME, or PHLX) from which the derivative securities are observed, the maturity of the underlying instruments (in the case of interest-rate derivatives), or multiple selections of an underlying.\n\nAn appropriate stationarity assumption for the dynamic behavior of the strike-tospot ratio $\\{k_{n}\\}$ is not as clear. In particular, the evolution of $\\{k_{n}\\}$ could be quite complicated, depending on the evolution over time of the strike-price grid, which is driven by detailed institutional features of the equity index option market. In this\n\n---\n\n[^1]: For exchange-traded derivatives, this situation of tme-varying contract variables almost always arises. In over-the-counter markets, however, contract variables on regularly quoted derivative prices are usually constant over time. See Brandt and Santa-Clara (2001) for an application to over-the-counter derivatives.\n\n[^2]: The \u201cmixing property of aMarkov chain canbeintuitively explainedbya physical analogue t location of a particle or gaseous mixture becomes less and less dependent on its initial position as time progress. See Gallant and White (1988) and references therein.\n\n<!-- Page:36 -->\n\npaper, our consistency result can be based on the assumption that $\\{k_{n}\\}$ is, joint with $\\left\\{y_{n},V_{n},q_{n},r_{n}\\right\\}$ ; geometrically ergodic, as stated more precisely below.\n\n### C.2. Consistency\n\nWe start with a formal definition of the option-implied volatility introduced in Section 3.1. Let $\\Xi\\subset[0,1]\\times\\Theta\\times\\mathbb{R}_{+}\\times\\mathbb{R}_{+}\\times\\mathbb{R}_{+}\\times\\mathbb{R}_{+}$ denote the domain of invertibility (with respect to volatility) of the option-pricing function $f$ of Eq. (3), in that $\\Xi$ is the maximal set for which a mapping $g:\\Xi\\to\\mathbb{R}_{+}$ is uniquely defined by\n\n$$\nf(g(c,\\, \\theta,\\, r,\\, q,\\, \\tau,\\, k),\\, \\theta,\\, r,\\, q,\\, \\tau,\\, k) = c \\tag{C.1}\n$$\n\nfor all $(c,\\vartheta,r,q,\\tau,k)\\in\\Xi$ : We suppose that the parameter space $\\boldsymbol{\\Theta}$ is defined so that, for any observation date $n$ and all $\\vartheta\\in\\Theta$ ; we have $(c_{n},\\vartheta,r_{n},q_{n},\\tau_{n},k_{n})\\in\\Xi$ : In effect, this is a joint property of the data and $\\boldsymbol{\\Theta}$ ; akin to an assumption that the model is not shown to be mis-specified. Indeed, in the empirical results to follow, inversion was possible at all data points. For any $\\boldsymbol{\\vartheta}\\in\\boldsymbol{\\Xi}$ ; we can therefore define the date- $n$ optionimplied volatility by\n\n$$\nV_{n}^{g} = g(c_n, \\vartheta, r_n, q_n, \\tau_n, k_n). \\tag{C.2}\n$$\n\nWe next establish the link between the option-implied volatility $V_{n}^{\\vartheta}$ and the true volatility state variable $V_{n}$ by letting $V_{n}^{9}=\\nu(V_{n}^{A},\\:\\mathbb{\\vec{y}},r_{n}^{A},q_{n}^{A},\\tau_{n},{\\:\\ddot{k}_{n}})$ ; where $\\nu$ : $\\mathbb{R}_{+}\\times\\theta\\times\\mathbb{R}_{+}\\times\\mathbb{R}_{+}\\times\\mathbb{R}_{+}\\times\\mathbb{R}_{+}\\to\\mathbb{R}_{+}$ is defined by\n\n$$\nv(v, \\vartheta, r, q, \\tau, k) = g(f(v, \\vartheta_0, r, q, \\tau, k), \\vartheta, r, q, \\tau, k), \\tag{C.3}\n$$\n\nwhere $g$ is defined by Eq. (C.1), using the fact that $c_{n}=f(V_{n}^{A},\\vartheta_{0},r_{n}^{A},q_{n}^{A},\\tau_{n},k_{n})$ : We note that $\\nu(v,\\vartheta_{0},r,q,\\tau,k)=v.$ :\n\nLetting $X_{n}=[y_{(n,n_{y})},V_{(n,n_{v})},r_{(n,n_{v})},q_{(n,n_{v})},k_{(n,n_{v})}]$ denote the \u2018 $\\mathbf{\\dot{\\rho}}_{n_{y}}$ -history\u2019\u2019 of $y$ and the \u2018 $\\cdot_{n_{v}}$ -histories\u2019\u2019 of $r,q,k_{;}$ ; and $\\tau$ ; and letting $Y_{n}=\\tau_{(n,n_{v})}$ denote the \u2018 $n_{v}$ -history\u2019\u2019 of $\\tau$ ; we write\n\n$$\nH(X_n, \\theta, Y_n) = h(y(n, n_y), v(V(n, n_v), \\theta, r(n, n_v), q(n, n_v), \\tau(n, n_v), k(n, n_v)), \\theta), \\tag{C.4}\n$$\n\nwhere $r_{(n,n_{v})}=[r_{n},r_{n-1},...,r_{n-n_{v}+1}],$ and, analogously, $q_{(n,n_{v})},k_{(n,n_{v})}$ ; and $\\tau_{(n,n_{v})}$ are the $n_{v}$ -dimensional vectors consisting of $q_{n},k_{n},\\tau_{n}$ ; and their respective lags. As outlined in the previous subsection, reasonable stationarity assumptions for $X$ and $Y$ are rather different, and are treated separately.\n\nAssumption C.1. (Time stationarity of $Y_{c}$ ). $\\{Y_{n}\\}$ has finitely many outcomes, denoted $\\{1,2,...,I\\}$ : For each outcome $i$ and each positive integer $N$ ; let $A_{N}^{(i)}=\\{n\\leqslant N:$ $Y_{n}=i\\}$ be the dates, up to $N$ ; on which $Y$ has outcome $i$ : For each $i.$ ; there is some $w_{i}\\in[0,1],$ such that\n\n$$\n\\lim_{N} \\frac{\\#A_N^{(i)}}{N} = w_i \\quad \\text{a.s.} \\tag{C.1}\n$$\n\nwhere $\\#(\\cdot)$ denotes cardinality.\n\n<!-- Page:37 -->\n\nFor a proof of the geometric ergodicity of the state vector $\\{y_{n},~V_{n},~r_{n},~q_{n}\\}$ ; see Appendix B.9 of Pan (2000). Assuming further that $\\{k_{n}\\}$ and $\\{y_{n},~V_{n},~r_{n},~q_{n}\\}$ are jointly geometrically ergodic, we know that $X_{n}=[y_{(n,n_{v})},V_{(n,n_{y})},r_{(n,n_{v})},$ ; $q_{(n,n_{v})},k_{(n,n_{v})}]$ is geometrically ergodic, since it includes only finitely many lags of the joint process.\n\nAssumption C.2. (USLLN of $\\boldsymbol{A}^{(i)}$ -sampling). For each outcome i of $Y$ ; letting\n\n$$\nG_N^{(i)}(\\theta) = \\frac{1}{\\#A_N^{(i)}} \\sum_{n \\in A_N^{(i)}} H(X_n, \\theta, i),\n$$\n\n$G_{\\infty}^{(i)}(\\vartheta)=\\mathrm{lim}_{N}G_{N}^{(i)}(\\vartheta)$ exists (pointwise SLLN), and\n\n$$\n\\sup_{\\theta \\in \\Theta} \\left| G_N^{(i)}(\\theta) - G_\\infty^{(i)}(\\theta) \\right| \\rightarrow 0 \\quad \\text{a.s.} \\tag{C.6}\n$$\n\nGiven the pointwise-SLLN portion of Assumption C.2, in order to establish the uniform SLLN of Assumption C.2, it is typical to assume some form of Lipschitz condition on $H(x,\\vartheta,i)$ as a function of W: Examples of such conditions include the Lipschitz and derivative conditions of Andrews (1987) and the first-momentcontinuity condition of Hansen (1982).\n\nWe now establish the uniform strong law of large numbers (USLLN) of $\\{H(X_{n},{\\mathcal{Y}},Y_{n})\\}$ ; key step to establishing the strong consistency of $\\{\\hat{\\mathcal{\\vartheta}}_{n}\\}$ : A proof can be found in Appendix B.8 in Pan (2000).\n\nProposition C.1. (USLLN of $H(X,~\\vartheta,~Y))$ . Under Assumptions C.1 and C.2, for each W; $G_{\\infty}(\\vartheta)=\\mathrm{lim}_{N}G_{N}(\\vartheta)$ exists, and\n\n$$\n\\sup_{\\theta \\in \\Theta} |G_N(\\theta) - G_{\\infty}(\\theta)| \\to 0 \\quad \\text{a.s.},\n$$\n\nwhere $G_{N}(\\mathcal{B})$ ; defined by Eq. (5), is the sample moment of the observation function.\n\nFinally, to show strong consistency of the IS-GMM estimator $\\{\\hat{\\mathcal{\\vartheta}}_{n}\\}$ ; we adopt the following two standard assumptions.\n\nAssumption C.3 (Convergence of weighting matrices). $\\mathcal{W}_{N}\\rightarrow\\mathcal{W}_{0}$ almost surely for some constant symmetric positive-definite matrix $\\mathcal{W}_{0}$ :\n\nUnder Assumption C.3 and the conditions of Proposition C.1, the criterion function $C_{N}(\\boldsymbol{\\vartheta})\\overset{\\cdot}{=}G_{N}(\\boldsymbol{\\vartheta})^{\\top}\\mathcal{W}_{N}G_{N}(\\boldsymbol{\\vartheta})$ converges almost surely to the asymptotic criterion function $C:\\Theta\\to\\mathbb{R}$ defined by $C_{N}(\\overset{\\cdot}{\\vartheta})=G_{\\infty}(\\vartheta)^{\\top}\\mathcal{W}_{N}\\overset{\\cdot}{G}_{\\infty}(\\vartheta)$ : In particular, we have $G(\\vartheta_{0})=0$ ; given the moment condition Eq. (2), the pointwise-SLLN portion of Proposition C.1, and the fact that $V_{n}^{9_{0}}=V_{n}^{\\varDelta}$ :\n\nAssumption C.4 (Uniqueness of minimizer). $C(\\vartheta)\\neq G(\\vartheta_{0}),\\vartheta\\in\\Theta,\\vartheta\\neq\\vartheta_{0}.$ :\n\n<!-- Page:38 -->\n\nTheorem C.1 (Strong consistency). Under Assumptions C.1\u2013C.4. the IS-GMM $\\{\\vartheta_{N}\\}$ estimator converges to $\\mathcal{\\mathrm{\\vartheta}}_{0}$ almost surely as $N\\to\\infty$ .\n\nGiven the Uniform SLLN (Proposition C.1), the proof is standard and omitted. (See, for example, the proof of Theorem 3.3 in Gallant and White, 1988.)",
"text_b": "#### C.2.1. Asymptotic normality\n\nNext, we establish asymptotic normality for the IS-GMM estimator, allowing for time-varying contract variables. Because $\\nu(v,\\vartheta_{0},r,q,\\tau,k)=v$ ; the sample moment $G_{N}(\\mathcal{G}_{0})$ evaluated at the true parameter $\\vartheta_{0}$ does not depend on the contract variables $\\{\\tau_{n},k_{n}\\}$ : Given the consistency result above, the asymptotic normality of $\\sqrt{N}G_{N}(\\mathcal{G}_{0})$ therefore depends only on the properties of $(y,V)$ and $h$ via a standard form of central limit theorem (CLT).\n\nAssumption C.5 (CLT). $\\sqrt{N}G_{N}(\\mathcal{vartheta}_{0})$ converges in distribution as $N\\to\\infty$ to a normal random vector with mean zero and some covariance matrix $\\scriptstyle\\sum_{0}$ :\n\nThis assumption follows immediately from the geometric ergodicity of $(y,V)$ and an assumption of integrability of $\\left|\\left|h(y_{(n,n_{y})},V_{(n,n_{v})})\\right|\\right|^{2+\\delta}$ ; for some $\\delta>0$ ; over the stationary distribution of $(y_{(n,n_{y})},\\dot{V_{(n,n_{v})}})$ . (See, for example, Theorem 7.5 of Doob, 1953; the proof of Theorem 4 of Duffie and Singleton, 1993.)\n\nThe asymptotic normality of $\\sqrt{N}(\\mathcal{\\vartheta}_{N}-\\mathcal{\\vartheta})$ depends further on the local behavior of the observation functions in a neighborhood of $\\vartheta_{0}$ ; and is influenced by the contract variables $\\{\\tau_{n},k_{n}\\}$ : For this, we consider the derivative $d(\\vartheta,X_{n},Y_{n})$ of $H(X_{n},{\\mathcal{S}},Y_{n})$ with respect to W; defined by\n\n$$\nd(\\vartheta, X_{n}, Y_{n}) = \\frac{\\partial}{\\partial \\vartheta} h\\left( y(n, n_{y}), \\; V^{\\vartheta}_{(n, n_{v})}, \\; \\vartheta \\right) \\\\ + \\sum_{i=n-n_{v}+1}^{n} \\frac{\\partial}{\\partial v_{i}} h\\left( y(n, n_{y}), \\; V^{\\vartheta}_{(n, n_{v})}, \\; \\vartheta \\right) g_{\\vartheta}\\left( c_{i}, \\; \\vartheta, \\; r_{i}^{A}, \\; q_{i}^{A}, \\; \\tau_{i}, \\; k_{i} \\right), \\tag{C.7}\n$$"
}
```

